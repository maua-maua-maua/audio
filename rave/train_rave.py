from os import environ, path

import GPUtil as gpu
import numpy as np
import pytorch_lightning as pl
import torch
from effortless_config import Config
from torch.utils.data import DataLoader, random_split
from udls import SimpleDataset, simple_audio_preprocess
from udls.transforms import Compose, Dequantize, RandomApply, RandomCrop

from rave.core import EMAModelCheckPoint, random_phase_mangle
from rave.model import RAVE

if __name__ == "__main__":

    class args(Config):
        DATA_SIZE = 16
        CAPACITY = 64
        LATENT_SIZE = 128
        RATIOS = [4, 4, 4, 2]
        BIAS = True
        NO_LATENCY = False

        LOUD_STRIDE = 1

        USE_NOISE = True
        NOISE_RATIOS = [4, 4, 4]
        NOISE_BANDS = 5

        D_CAPACITY = 16
        D_MULTIPLIER = 4
        D_N_LAYERS = 4

        WARMUP = 1000000
        MODE = "hinge"
        CKPT = None

        PREPROCESSED = None
        WAV = None
        SR = 48000
        N_SIGNAL = 65536

        BATCH = 8

        NAME = None

    args.parse_args()

    assert args.NAME is not None

    model = RAVE(
        data_size=args.DATA_SIZE,
        capacity=args.CAPACITY,
        latent_size=args.LATENT_SIZE,
        ratios=args.RATIOS,
        bias=args.BIAS,
        loud_stride=args.LOUD_STRIDE,
        use_noise=args.USE_NOISE,
        noise_ratios=args.NOISE_RATIOS,
        noise_bands=args.NOISE_BANDS,
        d_capacity=args.D_CAPACITY,
        d_multiplier=args.D_MULTIPLIER,
        d_n_layers=args.D_N_LAYERS,
        warmup=args.WARMUP,
        mode=args.MODE,
        no_latency=args.NO_LATENCY,
        sr=args.SR,
    )

    x = torch.zeros(args.BATCH, 2 ** 14)
    model.validation_step(x, 0)

    dataset = SimpleDataset(
        args.PREPROCESSED,
        args.WAV,
        preprocess_function=simple_audio_preprocess(args.SR, 2 * args.N_SIGNAL),
        split_set="full",
        transforms=Compose(
            [
                RandomCrop(args.N_SIGNAL),
                RandomApply(
                    lambda x: random_phase_mangle(x, 20, 2000, 0.99, args.SR),
                    p=0.8,
                ),
                Dequantize(16),
                lambda x: x.astype(np.float32),
            ]
        ),
    )

    val = (2 * len(dataset)) // 100
    train = len(dataset) - val
    train, val = random_split(dataset, [train, val])

    train = DataLoader(train, args.BATCH, True, drop_last=True, num_workers=8)
    val = DataLoader(val, args.BATCH, False, num_workers=8)

    # CHECKPOINT CALLBACKS
    validation_checkpoint = pl.callbacks.ModelCheckpoint(
        monitor="validation",
        filename="best",
    )
    last_checkpoint = pl.callbacks.ModelCheckpoint(filename="last")
    ema_checkpoint = EMAModelCheckPoint(model, filename="ema", monitor="validation")

    CUDA = gpu.getAvailable(maxMemory=0.05)
    if len(CUDA):
        environ["CUDA_VISIBLE_DEVICES"] = str(CUDA[0])
        use_gpu = 1
    elif torch.cuda.is_available():
        print("Cuda is available but no fully free GPU found.")
        print("Training may be slower due to concurrent processes.")
        use_gpu = 1
    else:
        print("No GPU found.")
        use_gpu = 0

    trainer = pl.Trainer(
        logger=pl.loggers.TensorBoardLogger(path.join("runs", args.NAME), name="rave"),
        gpus=use_gpu,
        val_check_interval=min(10000, len(train)),
        callbacks=[validation_checkpoint, last_checkpoint],  # , ema_checkpoint],
        resume_from_checkpoint=args.CKPT,
        max_epochs=100000,
    )
    trainer.fit(model, train, val)
